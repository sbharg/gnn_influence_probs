{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, Linear, SAGEConv, GATv2Conv, GATConv\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy as sp\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  ..., 99, 99, 99],\n",
      "        [ 9, 17, 38,  ..., 86, 88, 98]])\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(G: nx.DiGraph):\n",
    "  edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "  return edge_index\n",
    "\n",
    "n = 100\n",
    "p = 0.1\n",
    "gname = f\"er_{n}_{str(p).replace('.', '')}\"\n",
    "path = Path(f\"datasets/synthetic/{gname}\")\n",
    "\n",
    "with open(path / f\"graph.mtx\", \"rb\") as fh:\n",
    "  G = nx.from_scipy_sparse_array(sp.io.mmread(fh), create_using=nx.DiGraph)\n",
    "\n",
    "cascades = []\n",
    "for i in range(250):\n",
    "  with open(path / f\"diffusions/timestamps/{i}.txt\", \"r\") as fh:\n",
    "    cascade = []\n",
    "    for line in fh:\n",
    "      cascade.append(list(map(int, line.strip().split())))\n",
    "    cascades.append(cascade)\n",
    "\n",
    "#for k in (50, 100, 150, 200, 250):\n",
    "k = 100\n",
    "k_cascades = cascades[:k]\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "edge_index = create_dataset(G)\n",
    "print(edge_index)\n",
    "\n",
    "#model = GNNIndependentCascade(64, 16, n, m, num_layers=2)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#train_model(model, optimizer, data, k_cascades, 30, len(k_cascades) // 4)\n",
    "\n",
    "#model.eval()\n",
    "#print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadeGNN(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim=64, num_layers=3):\n",
    "        super(CascadeGNN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        \n",
    "        # Initial node embedding layer\n",
    "        self.node_embedding = nn.Embedding(num_nodes, hidden_dim)\n",
    "        \n",
    "        # GNN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "            \n",
    "        # Edge probability prediction layer\n",
    "        self.edge_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, edge_index):\n",
    "        # Get initial node embeddings\n",
    "        x = self.node_embedding(torch.arange(self.num_nodes).to(edge_index.device))\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "            \n",
    "        # Compute edge probabilities for all edges\n",
    "        edge_probabilities = {}\n",
    "        for i in range(edge_index.size(1)):\n",
    "            source, target = edge_index[:, i]\n",
    "            combined_features = torch.cat([x[source], x[target]], dim=0)\n",
    "            prob = self.edge_predictor(combined_features)\n",
    "            edge_probabilities[(source.item(), target.item())] = prob\n",
    "        \n",
    "        return edge_probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cascade_likelihood(num_nodes, edge_probs, cascade, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the negative log likelihood of observing a cascade given edge probabilities\n",
    "    \n",
    "    Args:\n",
    "        num_nodes: Number of nodes in the graph\n",
    "        edge_probs: Dictionary mapping (source, target) tuples to probabilities\n",
    "        cascade: List of lists, where cascade[i] contains nodes activated at time i\n",
    "        eps: Small value to prevent log(0)\n",
    "    \n",
    "    Returns:\n",
    "        Negative log likelihood of the cascade\n",
    "    \"\"\"\n",
    "    log_likelihood = 0.0\n",
    "    activated_nodes = set()\n",
    "    \n",
    "    # Process each time step\n",
    "    for t in range(len(cascade)):\n",
    "        prev_activated = cascade[t-1] if t-1 >= 0 else []\n",
    "        curr_activated = cascade[t]\n",
    "        next_activated = cascade[t+1] if t+1 < len(cascade) else []\n",
    "        activated_nodes.update(curr_activated)\n",
    "\n",
    "        #print(t)\n",
    "        #print(prev_activated)\n",
    "        #print(curr_activated)\n",
    "        #print(next_activated)\n",
    "\n",
    "        for v in curr_activated:\n",
    "            # Probability of activation from parents\n",
    "            if prev_activated:\n",
    "                parents = set([u for u in range(num_nodes) if (u, v) in edge_probs and u in prev_activated])\n",
    "                prob = [1 - edge_probs[(u, v)] for u in parents]\n",
    "                prob = torch.cat(prob)\n",
    "                prob_not_activated = torch.prod(prob)\n",
    "                log_likelihood += torch.log(1 - prob_not_activated + eps)\n",
    "            if next_activated:\n",
    "                children = set([w for w in range(num_nodes) if (v, w) in edge_probs and w not in activated_nodes and w not in set(next_activated)])\n",
    "                if not children:\n",
    "                    continue\n",
    "                prob = [1 - edge_probs[(v, w)] for w in children]\n",
    "                prob = torch.cat(prob)\n",
    "                #print(prob)\n",
    "                prob_not_activated = torch.prod(prob)\n",
    "                log_likelihood += torch.log(prob_not_activated + eps)\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "def compute_loss(num_nodes, edge_probs, edge_index, cascades):\n",
    "  \"\"\"\n",
    "  Compute the negative log-likelihood loss for multiple cascades.\n",
    "  \n",
    "  Args:\n",
    "    num_nodes: Number of nodes in the\n",
    "    edge_probs: Tensor of predicted edge probabilities\n",
    "    edge_index: Tensor of shape [2, num_edges] containing edge indices\n",
    "    cascades: List of cascades, where each cascade is a list of lists of activated nodes\n",
    "  \n",
    "  Returns:\n",
    "    loss: Negative log-likelihood loss\n",
    "  \"\"\"\n",
    "  total_log_likelihood = 0.0\n",
    "  for cascade in cascades:\n",
    "    total_log_likelihood += compute_cascade_likelihood(num_nodes, edge_probs, cascade)\n",
    "  \n",
    "  # Return negative log-likelihood as the loss\n",
    "  #print(-total_log_likelihood)\n",
    "  return -total_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cascade_gnn(model, num_nodes, edge_index, cascades, num_epochs=100, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train the GNN model using the observed cascades\n",
    "    \n",
    "    Args:\n",
    "        model: CascadeGNN model\n",
    "        num_nodes: Number of nodes in the graph\n",
    "        edge_index: Tensor of shape [2, num_edges] containing edge indices\n",
    "        cascades: List of cascades, where each cascade is a list of lists\n",
    "        num_epochs: Number of training epochs\n",
    "        lr: Learning rate\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get edge probabilities\n",
    "        edge_probs = model.forward(edge_index)\n",
    "        \n",
    "        # Compute total negative log likelihood across all cascades\n",
    "        total_loss = compute_loss(num_nodes, edge_probs, edge_index, cascades)\n",
    "            \n",
    "        # Backward pass and optimization\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.item():.4f}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 12770.5693\n",
      "Epoch 20/50, Loss: 11774.3955\n",
      "Epoch 30/50, Loss: 11555.9971\n",
      "Epoch 40/50, Loss: 11541.6787\n",
      "Epoch 50/50, Loss: 11544.8721\n"
     ]
    }
   ],
   "source": [
    "model = CascadeGNN(n, hidden_dim=64, num_layers=3)\n",
    "trained_model = train_cascade_gnn(model, n, edge_index, k_cascades, num_epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11307469791069746]\n"
     ]
    }
   ],
   "source": [
    "edge_probs = trained_model(edge_index)\n",
    "l1_errors = []\n",
    "#print(edge_probs)\n",
    "\n",
    "residuals = []\n",
    "for i, e in enumerate(G.edges()):\n",
    "  u, v = e\n",
    "  p = G[u][v]['weight']\n",
    "  residuals.append(abs(p - edge_probs[e].item()))\n",
    "\n",
    "l1_errors.append(sum(residuals) / len(residuals))\n",
    "print(l1_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
