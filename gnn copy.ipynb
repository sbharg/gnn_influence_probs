{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, Linear, SAGEConv, GATv2Conv, GATConv\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy as sp\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeAwareMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim):\n",
    "        super(EdgeAwareMessagePassing, self).__init__(aggr='add')\n",
    "        self.node_dim = node_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Message creation networks\n",
    "        self.message_nn = nn.Sequential(\n",
    "            nn.Linear(2 * node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Update networks\n",
    "        self.node_update = nn.GRUCell(hidden_dim, node_dim)\n",
    "        self.edge_update = nn.GRUCell(2 * hidden_dim, edge_dim)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(2 * node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Propagate messages\n",
    "        print(edge_index.shape)\n",
    "        print(x.shape)\n",
    "        print(edge_attr.shape)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # Combine source node, target node, and edge features\n",
    "        tmp = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        alpha = self.attention(tmp)\n",
    "        \n",
    "        # Create message\n",
    "        message = self.message_nn(tmp)\n",
    "        \n",
    "        return alpha * message\n",
    "\n",
    "    def update(self, aggr_out, x, edge_index, edge_attr):\n",
    "        # Update node features\n",
    "        x_new = self.node_update(aggr_out, x)\n",
    "        \n",
    "        # Update edge features\n",
    "        edge_features = []\n",
    "        for i in range(edge_index.size(1)):\n",
    "            source, target = edge_index[:, i]\n",
    "            combined = torch.cat([x_new[source], x_new[target]], dim=0)\n",
    "            edge_features.append(combined)\n",
    "        edge_features = torch.stack(edge_features, dim=0)\n",
    "        \n",
    "        edge_attr_new = self.edge_update(edge_features, edge_attr)\n",
    "        \n",
    "        return x_new, edge_attr_new\n",
    "\n",
    "class CascadeGNN(nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_dim=64, num_layers=3):\n",
    "        super(CascadeGNN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #self.edge_dim = edge_dim\n",
    "        \n",
    "        # Initial embeddings\n",
    "        self.node_embedding = nn.Embedding(num_nodes, hidden_dim)\n",
    "        #self.edge_embedding = nn.Parameter(torch.randn(edge_dim))\n",
    "        self.edge_embedding = nn.Parameter(torch.Tensor(self.num_nodes, self.num_nodes, hidden_dim))\n",
    "\n",
    "        '''\n",
    "        # Message passing layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            EdgeAwareMessagePassing(hidden_dim, edge_dim, hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Edge probability prediction layer\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        ''' \n",
    "        self.convs = nn.ModuleList([\n",
    "            GATConv(hidden_dim, hidden_dim) \n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, edge_index):\n",
    "        # Get initial node embeddings\n",
    "        x = self.node_embedding(torch.arange(self.num_nodes).to(edge_index.device))\n",
    "        # Initialize edge features (one per edge)\n",
    "        src, dst = edge_index\n",
    "        edge_attr = self.edge_embedding[src, dst]\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.gelu(x)\n",
    "            x = torch.dropout(x, p=0.1, train=self.training)\n",
    "            #x_new, edge_attr = conv(x, edge_index, edge_attr)\n",
    "            #x = x_new + x  # Residual connection for nodes\n",
    "            #edge_attr = edge_attr + edge_attr.clone()  # Residual connection for edges\n",
    "            \n",
    "        # Compute edge probabilities for all edges\n",
    "        edge_repr = torch.cat([torch.add(x[src], x[dst]), edge_attr], dim=1)\n",
    "        edge_probs = self.edge_mlp(edge_repr)\n",
    "        edge_probabilities = {}\n",
    "        for i in range(edge_index.size(1)):\n",
    "            source, target = edge_index[:, i]\n",
    "            edge_probabilities[(source.item(), target.item())] = edge_probs[i]\n",
    "        \n",
    "        return edge_probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNIndependentCascade(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim, n_nodes, num_layers=3):\n",
    "    super(GNNIndependentCascade, self).__init__()\n",
    "    self.n = n_nodes\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.node_embed = nn.Embedding(self.n, hidden_dim)\n",
    "    self.edge_embed = nn.Parameter(torch.Tensor(self.n, self.n, hidden_dim))\n",
    "\n",
    "    self.convs = nn.ModuleList([\n",
    "      GATConv(hidden_dim, hidden_dim) \n",
    "      for i in range(num_layers)\n",
    "    ])\n",
    "\n",
    "    self.edge_predictor = nn.Sequential(\n",
    "      nn.Linear(2*hidden_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, 1),\n",
    "    )\n",
    "    #nn.Linear(hidden_dim, 1)\n",
    "\n",
    "  def forward(self, edge_index):\n",
    "    x = self.node_embed(torch.arange(self.n))\n",
    "\n",
    "    src, dst = edge_index\n",
    "    edge_emb = self.edge_embed[src, dst]\n",
    "\n",
    "    # Node embedding\n",
    "    for i in range(self.num_layers):\n",
    "      #x = self.convs[i](x, edge_index, edge_emb)\n",
    "      x = self.convs[i](x, edge_index)\n",
    "      x = F.gelu(x)\n",
    "      x = torch.dropout(x, p=0.1, train=self.training)\n",
    "\n",
    "    # Edge probability prediction\n",
    "    #edge_repr = torch.cat([x[src], x[dst]], dim=1)\n",
    "    #edge_repr = torch.cat([torch.add(x[src], x[dst]), edge_emb], dim=1)\n",
    "    #edge_probs = torch.sigmoid(self.edge_predictor(edge_repr))\n",
    "    edge_probabilities = {}\n",
    "    for i in range(edge_index.size(1)):\n",
    "        source, target = edge_index[:, i]\n",
    "        edge_repr = torch.cat([torch.add(x[source], x[target]), edge_emb[i]], dim=0)\n",
    "        prob = torch.sigmoid(self.edge_predictor(edge_repr))\n",
    "        edge_probabilities[(source.item(), target.item())] = prob\n",
    "    \n",
    "    print(edge_probabilities)\n",
    "    return edge_probabilities\n",
    "    #edge_probs = torch.sigmoid(torch.sum(x[row] * x[col], dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cascade_likelihood(num_nodes, edge_probs, cascade, eps=1e-4):\n",
    "    \"\"\"\n",
    "    Compute the negative log likelihood of observing a cascade given edge probabilities\n",
    "    \n",
    "    Args:\n",
    "        num_nodes: Number of nodes in the graph\n",
    "        edge_probs: Dictionary mapping (source, target) tuples to probabilities\n",
    "        cascade: List of lists, where cascade[i] contains nodes activated at time i\n",
    "        eps: Small value to prevent log(0)\n",
    "    \n",
    "    Returns:\n",
    "        Negative log likelihood of the cascade\n",
    "    \"\"\"\n",
    "    log_likelihood = 0.0\n",
    "    activated_nodes = set()\n",
    "    \n",
    "    # Process each time step\n",
    "    for t in range(len(cascade)):\n",
    "        prev_activated = cascade[t-1] if t-1 >= 0 else []\n",
    "        curr_activated = cascade[t]\n",
    "        next_activated = cascade[t+1] if t+1 < len(cascade) else []\n",
    "        activated_nodes.update(curr_activated)\n",
    "\n",
    "        #print(t)\n",
    "        #print(prev_activated)\n",
    "        #print(curr_activated)\n",
    "        #print(next_activated)\n",
    "\n",
    "        for v in curr_activated:\n",
    "            # Probability of activation from parents\n",
    "            if prev_activated:\n",
    "                parents = set([u for u in range(num_nodes) if (u, v) in edge_probs and u in prev_activated])\n",
    "                prob = [1 - edge_probs[(u, v)] for u in parents]\n",
    "                prob = torch.cat(prob)\n",
    "                prob_not_activated = torch.prod(prob)\n",
    "                log_likelihood += torch.log(1 - prob_not_activated + eps)\n",
    "            if next_activated:\n",
    "                children = set([w for w in range(num_nodes) if (v, w) in edge_probs and w not in activated_nodes and w not in set(next_activated)])\n",
    "                if not children:\n",
    "                    continue\n",
    "                prob = [1 - edge_probs[(v, w)] for w in children]\n",
    "                prob = torch.cat(prob)\n",
    "                #print(prob)\n",
    "                prob_not_activated = torch.prod(prob)\n",
    "                log_likelihood += torch.log(prob_not_activated + eps)\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "def compute_loss(num_nodes, edge_probs, cascades):\n",
    "  \"\"\"\n",
    "  Compute the negative log-likelihood loss for multiple cascades.\n",
    "  \n",
    "  Args:\n",
    "    num_nodes: Number of nodes in the\n",
    "    edge_probs: Tensor of predicted edge probabilities\n",
    "    cascades: List of cascades, where each cascade is a list of lists of activated nodes\n",
    "  \n",
    "  Returns:\n",
    "    loss: Negative log-likelihood loss\n",
    "  \"\"\"\n",
    "  total_log_likelihood = 0.0\n",
    "  for cascade in cascades:\n",
    "    total_log_likelihood += compute_cascade_likelihood(num_nodes, edge_probs, cascade)\n",
    "  \n",
    "  # Return negative log-likelihood as the loss\n",
    "  #print(-total_log_likelihood)\n",
    "  return -total_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cascade_gnn(model, num_nodes, edge_index, adj_list, cascades, num_epochs=100, lr=0.001, verbose=True):\n",
    "    \"\"\"\n",
    "    Train the GNN model using the observed cascades\n",
    "    \n",
    "    Args:\n",
    "        model: CascadeGNN model\n",
    "        num_nodes: Number of nodes in the graph\n",
    "        edge_index: Tensor of shape [2, num_edges] containing edge indices\n",
    "        cascades: List of cascades, where each cascade is a list of lists\n",
    "        num_epochs: Number of training epochs\n",
    "        lr: Learning rate\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get edge probabilities\n",
    "        edge_probs = model.forward(edge_index)\n",
    "        \n",
    "        # Compute total negative log likelihood across all cascades\n",
    "        total_loss = compute_loss(num_nodes, edge_probs, cascades)\n",
    "            \n",
    "        # Backward pass and optimization\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss.item():.4f}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(G: nx.DiGraph):\n",
    "  edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "  adj_list = {v : (set(), set()) for v in G.nodes}\n",
    "  for e in G.edges:\n",
    "    u, v = e\n",
    "    adj_list[u][1].add(v)\n",
    "    adj_list[v][0].add(u)\n",
    "  return edge_index, adj_list\n",
    "\n",
    "n = 100\n",
    "p = 0.1\n",
    "gname = f\"er_{n}_{str(p).replace('.', '')}\"\n",
    "path = Path(f\"datasets/synthetic/{gname}\")\n",
    "\n",
    "with open(path / f\"graph.mtx\", \"rb\") as fh:\n",
    "  G = nx.from_scipy_sparse_array(sp.io.mmread(fh), create_using=nx.DiGraph)\n",
    "\n",
    "cascades = []\n",
    "for i in range(250):\n",
    "  with open(path / f\"diffusions/timestamps/{i}.txt\", \"r\") as fh:\n",
    "    cascade = []\n",
    "    for line in fh:\n",
    "      cascade.append(list(map(int, line.strip().split())))\n",
    "    cascades.append(cascade)\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "edge_index, adj_list = create_dataset(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#model = CascadeGNN(n, hidden_dim=64, num_layers=3)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m GNNIndependentCascade(\u001b[38;5;241m32\u001b[39m, n, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cascade_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascades\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(end\u001b[38;5;241m-\u001b[39mstart)\n",
      "Cell \u001b[0;32mIn[60], line 20\u001b[0m, in \u001b[0;36mtrain_cascade_gnn\u001b[0;34m(model, num_nodes, edge_index, cascades, num_epochs, lr, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Get edge probabilities\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m edge_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Compute total negative log likelihood across all cascades\u001b[39;00m\n\u001b[1;32m     23\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m compute_loss(num_nodes, edge_probs, cascades)\n",
      "Cell \u001b[0;32mIn[68], line 43\u001b[0m, in \u001b[0;36mGNNIndependentCascade.forward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     42\u001b[0m     source, target \u001b[38;5;241m=\u001b[39m edge_index[:, i]\n\u001b[0;32m---> 43\u001b[0m     edge_repr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43msource\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_predictor(edge_repr))\n\u001b[1;32m     45\u001b[0m     edge_probabilities[(source\u001b[38;5;241m.\u001b[39mitem(), target\u001b[38;5;241m.\u001b[39mitem())] \u001b[38;5;241m=\u001b[39m prob\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "l1_errors = []\n",
    "times = []\n",
    "cascade_sizes = [50, 75, 100]\n",
    "for k in cascade_sizes:\n",
    "    start = time.time()\n",
    "    #model = CascadeGNN(n, hidden_dim=64, num_layers=3)\n",
    "    model = GNNIndependentCascade(32, n, num_layers=2)\n",
    "    trained_model = train_cascade_gnn(model, n, edge_index, cascades[:k], num_epochs=40, lr=0.01, verbose=True)\n",
    "    end = time.time()\n",
    "    times.append(end-start)\n",
    "\n",
    "    trained_model.eval()\n",
    "    edge_probs = trained_model(edge_index)\n",
    "    residuals = []\n",
    "    for i, e in enumerate(G.edges()):\n",
    "        u, v = e\n",
    "        p = G[u][v]['weight']\n",
    "        residuals.append(abs(p - edge_probs[e].item()))\n",
    "\n",
    "    l1_errors.append(sum(residuals) / len(residuals))\n",
    "\n",
    "print(\"M\\tMAE\\t\\t\\tTime\")\n",
    "for i, k in enumerate(cascade_sizes):\n",
    "    print(f\"{k}\\t{l1_errors[i]}\\t{times[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11266553486120538, 0.11358482052435794, 0.11321353166009078]\n",
      "[53.8030731678009, 100.08372330665588, 145.98774337768555]\n"
     ]
    }
   ],
   "source": [
    "print(l1_errors)\n",
    "print(times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
