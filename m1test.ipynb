{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, Linear, SAGEConv, GATv2Conv, GATConv\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy as sp\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Comptuer Modern\",\n",
    "    \"font.size\"   : 12\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cascade_likelihood(edge_probs, edge_index, cascade, epsilon=1e-8):\n",
    "  \"\"\"\n",
    "  Compute the likelihood of observing a single cascade given edge probabilities.\n",
    "  \n",
    "  Args:\n",
    "  - edge_probs: Tensor of predicted edge probabilities\n",
    "  - edge_index: Tensor of shape [2, num_edges] containing edge indices\n",
    "  - cascade: List of lists, where each inner list contains nodes activated at that time step\n",
    "  - epsilon: Small value to avoid log(0)\n",
    "  \n",
    "  Returns:\n",
    "  - log_likelihood: Log-likelihood of the cascade\n",
    "  \"\"\"\n",
    "  device = edge_probs.device\n",
    "  num_nodes = edge_index.max().item() + 1\n",
    "  activated = torch.zeros(num_nodes, dtype=torch.bool, device=device)\n",
    "  log_likelihood = 0.0\n",
    "\n",
    "  src, dst = edge_index\n",
    "\n",
    "  for t in range(len(cascade)):\n",
    "    prev_activated = torch.tensor(cascade[t-1] if t-1 >= 0 else [], device=device)\n",
    "    curr_activated = torch.tensor(cascade[t], device=device)\n",
    "    next_activated = torch.tensor(cascade[t+1] if t+1 < len(cascade) else [], device=device)\n",
    "    activated[curr_activated] = True\n",
    "    \n",
    "    for v in curr_activated:\n",
    "      # Probability of activation from parents\n",
    "      parents = src[(dst == v) & activated[src]]\n",
    "      activated_parents = parents[torch.isin(parents, prev_activated)]\n",
    "      if len(activated_parents) > 0:\n",
    "        prob_v_activated = 1 - torch.prod(1 - edge_probs[torch.isin(src, activated_parents) & (dst == v)])\n",
    "        log_likelihood += torch.log(prob_v_activated + epsilon)\n",
    "\n",
    "      # Probability of non-activation of children\n",
    "      children = dst[(src == v) & ~activated[dst]]\n",
    "      non_activated_children = children[~torch.isin(children, next_activated)]\n",
    "      if len(non_activated_children) > 0:\n",
    "        prob_children_not_activated = torch.prod(1 - edge_probs[(src == v) & torch.isin(dst, non_activated_children)])\n",
    "        log_likelihood += torch.log(prob_children_not_activated + epsilon)\n",
    "        \n",
    "  return log_likelihood\n",
    "\n",
    "def compute_loss(edge_probs, edge_index, cascades):\n",
    "  \"\"\"\n",
    "  Compute the negative log-likelihood loss for multiple cascades.\n",
    "  \n",
    "  Args:\n",
    "  - edge_probs: Tensor of predicted edge probabilities\n",
    "  - edge_index: Tensor of shape [2, num_edges] containing edge indices\n",
    "  - cascades: List of cascades, where each cascade is a list of lists of activated nodes\n",
    "  \n",
    "  Returns:\n",
    "  - loss: Negative log-likelihood loss\n",
    "  \"\"\"\n",
    "  total_log_likelihood = 0.0\n",
    "  for cascade in cascades:\n",
    "    total_log_likelihood += compute_cascade_likelihood(edge_probs, edge_index, cascade)\n",
    "  \n",
    "  # Return negative log-likelihood as the loss\n",
    "  return -total_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNIndependentCascade(torch.nn.Module):\n",
    "  def __init__(self, node_emb_dim, hidden_dim, n_nodes, n_edges, num_layers=2):\n",
    "    super(GNNIndependentCascade, self).__init__()\n",
    "    self.n = n_nodes\n",
    "    self.m = n_edges\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.node_embed = nn.Embedding(self.n, node_emb_dim)\n",
    "    self.edge_embed = nn.Parameter(torch.Tensor(self.n, self.n, hidden_dim))\n",
    "\n",
    "    self.convs = nn.ModuleList([\n",
    "      GATConv(node_emb_dim if i == 0 else hidden_dim, hidden_dim) \n",
    "      for i in range(num_layers)\n",
    "    ])\n",
    "\n",
    "    self.edge_predictor = nn.Sequential(\n",
    "      nn.Linear(2*hidden_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, 1),\n",
    "    )\n",
    "    #nn.Linear(hidden_dim, 1)\n",
    "\n",
    "  def forward(self, data):\n",
    "    edge_index = data.edge_index\n",
    "    x = self.node_embed(torch.arange(self.n))\n",
    "\n",
    "    src, dst = edge_index\n",
    "    edge_emb = self.edge_embed[src, dst]\n",
    "\n",
    "    # Node embedding\n",
    "    for i in range(self.num_layers):\n",
    "      #x = self.convs[i](x, edge_index, edge_emb)\n",
    "      x = self.convs[i](x, edge_index)\n",
    "      x = F.gelu(x)\n",
    "      x = torch.dropout(x, p=0.1, train=self.training)\n",
    "\n",
    "    # Edge probability prediction\n",
    "    #edge_repr = torch.cat([x[src], x[dst]], dim=1)\n",
    "    edge_repr = torch.cat([torch.add(x[src], x[dst]), edge_emb], dim=1)\n",
    "    edge_probs = torch.sigmoid(self.edge_predictor(edge_repr))\n",
    "\n",
    "    #edge_probs = torch.sigmoid(torch.sum(x[row] * x[col], dim=1))\n",
    "\n",
    "    return edge_probs\n",
    "\n",
    "def train_model(model, optimizer, data, cascades, num_epochs, batch_size = 50):\n",
    "  model.train()\n",
    "  #batches = DataLoader(cascades, batch_size=10, shuffle=True)\n",
    "  #print(batches)\n",
    "\n",
    "  print(f\"Training model (k = {len(cascades)})...\")\n",
    "  for epoch in range(num_epochs):\n",
    "    loss = 0.0\n",
    "    rng.shuffle(cascades)\n",
    "    batches = [cascades[i:i+batch_size] for i in range(0, len(cascades), batch_size)]\n",
    "\n",
    "    for batch in batches:\n",
    "      optimizer.zero_grad()\n",
    "      edge_probs = model.forward(data)\n",
    "\n",
    "      batch_loss = compute_loss(edge_probs, data.edge_index, batch)\n",
    "      batch_loss.backward()\n",
    "      optimizer.step()\n",
    "      loss += batch_loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {loss / len(cascades):.4f}\")\n",
    "  \n",
    "  print(\"Training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(G: nx.DiGraph, features):\n",
    "  edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "  data = Data(x=features, edge_index=edge_index)\n",
    "  return data\n",
    "\n",
    "n = 100\n",
    "p = 0.1\n",
    "gname = f\"er_{n}_{str(p).replace('.', '')}\"\n",
    "path = Path(f\"datasets/synthetic/{gname}\")\n",
    "\n",
    "with open(path / f\"graph.mtx\", \"rb\") as fh:\n",
    "  G = nx.from_scipy_sparse_array(sp.io.mmread(fh), create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model (k = 100)...\n",
      "Epoch 1/30, Avg Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m GNNIndependentCascade(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m16\u001b[39m, n, m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     26\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_cascades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk_cascades\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, data, cascades, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     60\u001b[0m edge_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(data)\n\u001b[0;32m---> 62\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(edge_probs, edge_index, cascades)\u001b[0m\n\u001b[1;32m     56\u001b[0m total_log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cascade \u001b[38;5;129;01min\u001b[39;00m cascades:\n\u001b[0;32m---> 58\u001b[0m   total_log_likelihood \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cascade_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascade\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Return negative log-likelihood as the loss\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mtotal_log_likelihood\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mcompute_cascade_likelihood\u001b[0;34m(edge_probs, edge_index, cascade, epsilon)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m curr_activated:\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;66;03m# Probability of activation from parents\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   parents \u001b[38;5;241m=\u001b[39m src[(dst \u001b[38;5;241m==\u001b[39m v) \u001b[38;5;241m&\u001b[39m activated[src]]\n\u001b[0;32m---> 30\u001b[0m   activated_parents \u001b[38;5;241m=\u001b[39m parents[\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_activated\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(activated_parents) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     prob_v_activated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mprod(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m edge_probs[torch\u001b[38;5;241m.\u001b[39misin(src, activated_parents) \u001b[38;5;241m&\u001b[39m (dst \u001b[38;5;241m==\u001b[39m v)])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l1_errors = []\n",
    "medians = []\n",
    "quartile1s = []\n",
    "quartile3s = []\n",
    "probs = []\n",
    "\n",
    "cascades = []\n",
    "#idxes = rng.choice(1000, 250, replace=False)\n",
    "for i in range(250):\n",
    "  with open(path / f\"diffusions/timestamps/{i}.txt\", \"r\") as fh:\n",
    "    cascade = []\n",
    "    for line in fh:\n",
    "      cascade.append(list(map(int, line.strip().split())))\n",
    "    cascades.append(cascade)\n",
    "\n",
    "#for k in (50, 100, 150, 200, 250):\n",
    "k = 100\n",
    "k_cascades = cascades[:k]\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "features = torch.eye(n)\n",
    "data = create_dataset(G, features)\n",
    "\n",
    "model = GNNIndependentCascade(64, 16, n, m, num_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "train_model(model, optimizer, data, k_cascades, 30, len(k_cascades) // 4)\n",
    "\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Error: 0.0962344105105303\n",
      "Median: 0.07501721677780152, Q1: 0.033743554198169705, Q3: 0.13690943005800246\n",
      "tensor([[0.1515],\n",
      "        [0.1624],\n",
      "        [0.3514],\n",
      "        [0.1484],\n",
      "        [0.2464],\n",
      "        [0.3846],\n",
      "        [0.1127],\n",
      "        [0.6354],\n",
      "        [0.0223],\n",
      "        [0.4870],\n",
      "        [0.5183],\n",
      "        [0.3458],\n",
      "        [0.6265],\n",
      "        [0.0311],\n",
      "        [0.4289],\n",
      "        [0.4145],\n",
      "        [0.3299],\n",
      "        [0.6229],\n",
      "        [0.6038],\n",
      "        [0.3562],\n",
      "        [0.2330],\n",
      "        [0.5073],\n",
      "        [0.3864],\n",
      "        [0.3456],\n",
      "        [0.3659],\n",
      "        [0.0219],\n",
      "        [0.5274],\n",
      "        [0.2631],\n",
      "        [0.1943],\n",
      "        [0.4451],\n",
      "        [0.2927],\n",
      "        [0.5784],\n",
      "        [0.1350],\n",
      "        [0.5750],\n",
      "        [0.2198],\n",
      "        [0.2942],\n",
      "        [0.0729],\n",
      "        [0.2936],\n",
      "        [0.5938],\n",
      "        [0.2052],\n",
      "        [0.6252],\n",
      "        [0.1465],\n",
      "        [0.0475],\n",
      "        [0.4688],\n",
      "        [0.6332],\n",
      "        [0.0335],\n",
      "        [0.4618],\n",
      "        [0.5180],\n",
      "        [0.2503],\n",
      "        [0.4973],\n",
      "        [0.2851],\n",
      "        [0.0944],\n",
      "        [0.4164],\n",
      "        [0.6291],\n",
      "        [0.3619],\n",
      "        [0.2586],\n",
      "        [0.5261],\n",
      "        [0.1093],\n",
      "        [0.2697],\n",
      "        [0.4831],\n",
      "        [0.5624],\n",
      "        [0.6612],\n",
      "        [0.2057],\n",
      "        [0.1360],\n",
      "        [0.2407],\n",
      "        [0.1986],\n",
      "        [0.1940],\n",
      "        [0.3904],\n",
      "        [0.6295],\n",
      "        [0.3418],\n",
      "        [0.0657],\n",
      "        [0.2779],\n",
      "        [0.6106],\n",
      "        [0.5534],\n",
      "        [0.2908],\n",
      "        [0.2525],\n",
      "        [0.5982],\n",
      "        [0.2190],\n",
      "        [0.4405],\n",
      "        [0.4452],\n",
      "        [0.3891],\n",
      "        [0.0271],\n",
      "        [0.2309],\n",
      "        [0.2949],\n",
      "        [0.5191],\n",
      "        [0.2061],\n",
      "        [0.2166],\n",
      "        [0.5449],\n",
      "        [0.0812],\n",
      "        [0.0390],\n",
      "        [0.5374],\n",
      "        [0.0891],\n",
      "        [0.3911],\n",
      "        [0.3736],\n",
      "        [0.4000],\n",
      "        [0.3718],\n",
      "        [0.2962],\n",
      "        [0.2243],\n",
      "        [0.3547],\n",
      "        [0.4054],\n",
      "        [0.2776],\n",
      "        [0.3128],\n",
      "        [0.2411],\n",
      "        [0.4022],\n",
      "        [0.5101],\n",
      "        [0.1791],\n",
      "        [0.4501],\n",
      "        [0.3135],\n",
      "        [0.4961],\n",
      "        [0.1057],\n",
      "        [0.0259],\n",
      "        [0.3708],\n",
      "        [0.2953],\n",
      "        [0.0275],\n",
      "        [0.5533],\n",
      "        [0.6040],\n",
      "        [0.2554],\n",
      "        [0.2581],\n",
      "        [0.2270],\n",
      "        [0.3044],\n",
      "        [0.2811],\n",
      "        [0.6045],\n",
      "        [0.2569],\n",
      "        [0.2610],\n",
      "        [0.0563],\n",
      "        [0.3380],\n",
      "        [0.4470],\n",
      "        [0.4759],\n",
      "        [0.2605],\n",
      "        [0.3399],\n",
      "        [0.2826],\n",
      "        [0.5100],\n",
      "        [0.0683],\n",
      "        [0.0692],\n",
      "        [0.0212],\n",
      "        [0.3503],\n",
      "        [0.2562],\n",
      "        [0.3264],\n",
      "        [0.5541],\n",
      "        [0.0265],\n",
      "        [0.5348],\n",
      "        [0.3090],\n",
      "        [0.3607],\n",
      "        [0.2542],\n",
      "        [0.0809],\n",
      "        [0.3359],\n",
      "        [0.3034],\n",
      "        [0.0345],\n",
      "        [0.1082],\n",
      "        [0.0598],\n",
      "        [0.1216],\n",
      "        [0.2620],\n",
      "        [0.1275],\n",
      "        [0.6232],\n",
      "        [0.1104],\n",
      "        [0.4768],\n",
      "        [0.2202],\n",
      "        [0.2407],\n",
      "        [0.0836],\n",
      "        [0.2747],\n",
      "        [0.5171],\n",
      "        [0.2655],\n",
      "        [0.5292],\n",
      "        [0.3496],\n",
      "        [0.5588],\n",
      "        [0.0528],\n",
      "        [0.3434],\n",
      "        [0.0719],\n",
      "        [0.2652],\n",
      "        [0.0737],\n",
      "        [0.3341],\n",
      "        [0.3474],\n",
      "        [0.4500],\n",
      "        [0.2733],\n",
      "        [0.2546],\n",
      "        [0.0676],\n",
      "        [0.1696],\n",
      "        [0.5157],\n",
      "        [0.3990],\n",
      "        [0.3330],\n",
      "        [0.0731],\n",
      "        [0.0673],\n",
      "        [0.2365],\n",
      "        [0.2512],\n",
      "        [0.3123],\n",
      "        [0.1195],\n",
      "        [0.0629],\n",
      "        [0.0725],\n",
      "        [0.0260],\n",
      "        [0.3107],\n",
      "        [0.3084],\n",
      "        [0.0814],\n",
      "        [0.4083],\n",
      "        [0.1863],\n",
      "        [0.1743],\n",
      "        [0.3614],\n",
      "        [0.2097],\n",
      "        [0.5415],\n",
      "        [0.5681],\n",
      "        [0.2889],\n",
      "        [0.0267],\n",
      "        [0.3387],\n",
      "        [0.1677],\n",
      "        [0.2730],\n",
      "        [0.6422],\n",
      "        [0.2518],\n",
      "        [0.6026],\n",
      "        [0.2982],\n",
      "        [0.4488],\n",
      "        [0.4954],\n",
      "        [0.0272],\n",
      "        [0.1449],\n",
      "        [0.2920],\n",
      "        [0.1628],\n",
      "        [0.4317],\n",
      "        [0.1557],\n",
      "        [0.0758],\n",
      "        [0.4169],\n",
      "        [0.0313],\n",
      "        [0.0788],\n",
      "        [0.1677],\n",
      "        [0.3202],\n",
      "        [0.1618],\n",
      "        [0.6357],\n",
      "        [0.5246],\n",
      "        [0.0494],\n",
      "        [0.6367],\n",
      "        [0.1492],\n",
      "        [0.5419],\n",
      "        [0.1867],\n",
      "        [0.5873],\n",
      "        [0.5091],\n",
      "        [0.0439],\n",
      "        [0.2041],\n",
      "        [0.2874],\n",
      "        [0.2247],\n",
      "        [0.3163],\n",
      "        [0.1774],\n",
      "        [0.4123],\n",
      "        [0.3193],\n",
      "        [0.5117],\n",
      "        [0.0624],\n",
      "        [0.1390],\n",
      "        [0.3580],\n",
      "        [0.5430],\n",
      "        [0.0379],\n",
      "        [0.1747],\n",
      "        [0.3818],\n",
      "        [0.5413],\n",
      "        [0.1517],\n",
      "        [0.2191],\n",
      "        [0.0712],\n",
      "        [0.2882],\n",
      "        [0.3237],\n",
      "        [0.2730],\n",
      "        [0.1390],\n",
      "        [0.0353],\n",
      "        [0.3035],\n",
      "        [0.2916],\n",
      "        [0.4910],\n",
      "        [0.0410],\n",
      "        [0.1769],\n",
      "        [0.1561],\n",
      "        [0.4837],\n",
      "        [0.3607],\n",
      "        [0.3903],\n",
      "        [0.2867],\n",
      "        [0.1483],\n",
      "        [0.0219],\n",
      "        [0.3572],\n",
      "        [0.4100],\n",
      "        [0.3869],\n",
      "        [0.1995],\n",
      "        [0.2643],\n",
      "        [0.1037],\n",
      "        [0.3353],\n",
      "        [0.3888],\n",
      "        [0.3588],\n",
      "        [0.4450],\n",
      "        [0.3251],\n",
      "        [0.0226],\n",
      "        [0.5213],\n",
      "        [0.3500],\n",
      "        [0.2631],\n",
      "        [0.4249],\n",
      "        [0.2107],\n",
      "        [0.5989],\n",
      "        [0.0249],\n",
      "        [0.3722],\n",
      "        [0.3242],\n",
      "        [0.1649],\n",
      "        [0.2354],\n",
      "        [0.3292],\n",
      "        [0.2106],\n",
      "        [0.5360],\n",
      "        [0.0387],\n",
      "        [0.0993],\n",
      "        [0.1441],\n",
      "        [0.3585],\n",
      "        [0.2780],\n",
      "        [0.2766],\n",
      "        [0.1949],\n",
      "        [0.6296],\n",
      "        [0.3451],\n",
      "        [0.3315],\n",
      "        [0.2592],\n",
      "        [0.3616],\n",
      "        [0.0523],\n",
      "        [0.3552],\n",
      "        [0.2271],\n",
      "        [0.6177],\n",
      "        [0.0790],\n",
      "        [0.2368],\n",
      "        [0.2353],\n",
      "        [0.3154],\n",
      "        [0.6197],\n",
      "        [0.2294],\n",
      "        [0.3725],\n",
      "        [0.2837],\n",
      "        [0.6034],\n",
      "        [0.2002],\n",
      "        [0.1253],\n",
      "        [0.0269],\n",
      "        [0.1481],\n",
      "        [0.6183],\n",
      "        [0.3630],\n",
      "        [0.5581],\n",
      "        [0.1681],\n",
      "        [0.1436],\n",
      "        [0.2797],\n",
      "        [0.2913],\n",
      "        [0.1880],\n",
      "        [0.3388],\n",
      "        [0.2753],\n",
      "        [0.2118],\n",
      "        [0.3669],\n",
      "        [0.5468],\n",
      "        [0.3419],\n",
      "        [0.0371],\n",
      "        [0.1811],\n",
      "        [0.3644],\n",
      "        [0.3597],\n",
      "        [0.2086],\n",
      "        [0.3729],\n",
      "        [0.1514],\n",
      "        [0.3380],\n",
      "        [0.0577],\n",
      "        [0.3133],\n",
      "        [0.3264],\n",
      "        [0.1172],\n",
      "        [0.2438],\n",
      "        [0.2169],\n",
      "        [0.6000],\n",
      "        [0.0577],\n",
      "        [0.6809],\n",
      "        [0.6246],\n",
      "        [0.3498],\n",
      "        [0.4299],\n",
      "        [0.3311],\n",
      "        [0.3658],\n",
      "        [0.2810],\n",
      "        [0.0465],\n",
      "        [0.6046],\n",
      "        [0.3168],\n",
      "        [0.0243],\n",
      "        [0.0790],\n",
      "        [0.2410],\n",
      "        [0.3383],\n",
      "        [0.3564],\n",
      "        [0.4375],\n",
      "        [0.3800],\n",
      "        [0.2864],\n",
      "        [0.1629],\n",
      "        [0.4735],\n",
      "        [0.6558],\n",
      "        [0.1696],\n",
      "        [0.2218],\n",
      "        [0.2224],\n",
      "        [0.0261],\n",
      "        [0.2189],\n",
      "        [0.0329],\n",
      "        [0.0265],\n",
      "        [0.0364],\n",
      "        [0.0242],\n",
      "        [0.1881],\n",
      "        [0.0197],\n",
      "        [0.5268],\n",
      "        [0.4147],\n",
      "        [0.2530],\n",
      "        [0.1626],\n",
      "        [0.2571],\n",
      "        [0.2088],\n",
      "        [0.1129],\n",
      "        [0.6286],\n",
      "        [0.4095],\n",
      "        [0.5928],\n",
      "        [0.0208],\n",
      "        [0.0453],\n",
      "        [0.5322],\n",
      "        [0.5395],\n",
      "        [0.3281],\n",
      "        [0.3352],\n",
      "        [0.5774],\n",
      "        [0.5722],\n",
      "        [0.1887],\n",
      "        [0.4172],\n",
      "        [0.5112],\n",
      "        [0.2811],\n",
      "        [0.5310],\n",
      "        [0.2414],\n",
      "        [0.0496],\n",
      "        [0.2032],\n",
      "        [0.1402],\n",
      "        [0.5864],\n",
      "        [0.2507],\n",
      "        [0.0421],\n",
      "        [0.0489],\n",
      "        [0.0353],\n",
      "        [0.3054],\n",
      "        [0.3709],\n",
      "        [0.0596],\n",
      "        [0.2137],\n",
      "        [0.5812],\n",
      "        [0.3240],\n",
      "        [0.1604],\n",
      "        [0.0632],\n",
      "        [0.2575],\n",
      "        [0.3829],\n",
      "        [0.5089],\n",
      "        [0.0417],\n",
      "        [0.6354],\n",
      "        [0.3258],\n",
      "        [0.2204],\n",
      "        [0.1064],\n",
      "        [0.5207],\n",
      "        [0.1755],\n",
      "        [0.3763],\n",
      "        [0.5958],\n",
      "        [0.6064],\n",
      "        [0.4011],\n",
      "        [0.1307],\n",
      "        [0.1508],\n",
      "        [0.5417],\n",
      "        [0.6484],\n",
      "        [0.6356],\n",
      "        [0.0468],\n",
      "        [0.3517],\n",
      "        [0.4453],\n",
      "        [0.5250],\n",
      "        [0.0373],\n",
      "        [0.5522],\n",
      "        [0.2210],\n",
      "        [0.2838],\n",
      "        [0.3083],\n",
      "        [0.1807],\n",
      "        [0.2158],\n",
      "        [0.0266],\n",
      "        [0.4228],\n",
      "        [0.6370],\n",
      "        [0.2825],\n",
      "        [0.2129],\n",
      "        [0.1543],\n",
      "        [0.3324],\n",
      "        [0.5725],\n",
      "        [0.0891],\n",
      "        [0.0392],\n",
      "        [0.6134],\n",
      "        [0.5551],\n",
      "        [0.2424],\n",
      "        [0.0385],\n",
      "        [0.5349],\n",
      "        [0.0302],\n",
      "        [0.1551],\n",
      "        [0.2205],\n",
      "        [0.0880],\n",
      "        [0.0243],\n",
      "        [0.1050],\n",
      "        [0.4697],\n",
      "        [0.5894],\n",
      "        [0.5382],\n",
      "        [0.2696],\n",
      "        [0.1338],\n",
      "        [0.5199],\n",
      "        [0.4513],\n",
      "        [0.3388],\n",
      "        [0.0672],\n",
      "        [0.3507],\n",
      "        [0.6033],\n",
      "        [0.2577],\n",
      "        [0.4407],\n",
      "        [0.5393],\n",
      "        [0.5253],\n",
      "        [0.5749],\n",
      "        [0.5897],\n",
      "        [0.2532],\n",
      "        [0.1735],\n",
      "        [0.1871],\n",
      "        [0.5334],\n",
      "        [0.5647],\n",
      "        [0.2168],\n",
      "        [0.3242],\n",
      "        [0.3416],\n",
      "        [0.3935],\n",
      "        [0.1534],\n",
      "        [0.3518],\n",
      "        [0.1184],\n",
      "        [0.0231],\n",
      "        [0.2915],\n",
      "        [0.2536],\n",
      "        [0.5207],\n",
      "        [0.3178],\n",
      "        [0.5872],\n",
      "        [0.2436],\n",
      "        [0.5832],\n",
      "        [0.2594],\n",
      "        [0.2337],\n",
      "        [0.1420],\n",
      "        [0.4040],\n",
      "        [0.6307],\n",
      "        [0.6042],\n",
      "        [0.2413],\n",
      "        [0.2295],\n",
      "        [0.5781],\n",
      "        [0.4107],\n",
      "        [0.0665],\n",
      "        [0.5709],\n",
      "        [0.4027],\n",
      "        [0.2803],\n",
      "        [0.1619],\n",
      "        [0.5883],\n",
      "        [0.0542],\n",
      "        [0.1530],\n",
      "        [0.5105],\n",
      "        [0.3309],\n",
      "        [0.0268],\n",
      "        [0.3300],\n",
      "        [0.3039],\n",
      "        [0.0976],\n",
      "        [0.4326],\n",
      "        [0.2028],\n",
      "        [0.4080],\n",
      "        [0.5391],\n",
      "        [0.1846],\n",
      "        [0.0480],\n",
      "        [0.3468],\n",
      "        [0.0770],\n",
      "        [0.2157],\n",
      "        [0.2659],\n",
      "        [0.3348],\n",
      "        [0.5163],\n",
      "        [0.1708],\n",
      "        [0.0275],\n",
      "        [0.5080],\n",
      "        [0.2594],\n",
      "        [0.1817],\n",
      "        [0.6148],\n",
      "        [0.3837],\n",
      "        [0.0541],\n",
      "        [0.3272],\n",
      "        [0.5503],\n",
      "        [0.3906],\n",
      "        [0.2962],\n",
      "        [0.1981],\n",
      "        [0.4274],\n",
      "        [0.5612],\n",
      "        [0.2731],\n",
      "        [0.1389],\n",
      "        [0.0470],\n",
      "        [0.1427],\n",
      "        [0.4922],\n",
      "        [0.4287],\n",
      "        [0.1061],\n",
      "        [0.2822],\n",
      "        [0.3519],\n",
      "        [0.5271],\n",
      "        [0.5733],\n",
      "        [0.6102],\n",
      "        [0.3661],\n",
      "        [0.2940],\n",
      "        [0.2584],\n",
      "        [0.4484],\n",
      "        [0.1835],\n",
      "        [0.4094],\n",
      "        [0.0556],\n",
      "        [0.2702],\n",
      "        [0.5378],\n",
      "        [0.0789],\n",
      "        [0.1633],\n",
      "        [0.0816],\n",
      "        [0.0622],\n",
      "        [0.5696],\n",
      "        [0.5908],\n",
      "        [0.3270],\n",
      "        [0.1842],\n",
      "        [0.5158],\n",
      "        [0.4461],\n",
      "        [0.2705],\n",
      "        [0.1515],\n",
      "        [0.0889],\n",
      "        [0.3606],\n",
      "        [0.4058],\n",
      "        [0.5680],\n",
      "        [0.3177],\n",
      "        [0.5407],\n",
      "        [0.5771],\n",
      "        [0.2370],\n",
      "        [0.2457],\n",
      "        [0.2631],\n",
      "        [0.2136],\n",
      "        [0.1098],\n",
      "        [0.3035],\n",
      "        [0.2588],\n",
      "        [0.2876],\n",
      "        [0.2587],\n",
      "        [0.2193],\n",
      "        [0.1893],\n",
      "        [0.4778],\n",
      "        [0.6198],\n",
      "        [0.2219],\n",
      "        [0.0708],\n",
      "        [0.4512],\n",
      "        [0.0256],\n",
      "        [0.3688],\n",
      "        [0.3401],\n",
      "        [0.2460],\n",
      "        [0.3382],\n",
      "        [0.4775],\n",
      "        [0.1799],\n",
      "        [0.1714],\n",
      "        [0.6058],\n",
      "        [0.0443],\n",
      "        [0.1830],\n",
      "        [0.5191],\n",
      "        [0.1901],\n",
      "        [0.0751],\n",
      "        [0.5906],\n",
      "        [0.6273],\n",
      "        [0.5875],\n",
      "        [0.3296],\n",
      "        [0.3999],\n",
      "        [0.2771],\n",
      "        [0.5987],\n",
      "        [0.0798],\n",
      "        [0.6186],\n",
      "        [0.1521],\n",
      "        [0.2719],\n",
      "        [0.4497],\n",
      "        [0.1708],\n",
      "        [0.4201],\n",
      "        [0.2504],\n",
      "        [0.2360],\n",
      "        [0.5319],\n",
      "        [0.2901],\n",
      "        [0.0322],\n",
      "        [0.0283],\n",
      "        [0.2241],\n",
      "        [0.0213],\n",
      "        [0.0306],\n",
      "        [0.4653],\n",
      "        [0.5562],\n",
      "        [0.2557],\n",
      "        [0.1170],\n",
      "        [0.3424],\n",
      "        [0.0449],\n",
      "        [0.2226],\n",
      "        [0.6185],\n",
      "        [0.2749],\n",
      "        [0.3333],\n",
      "        [0.4045],\n",
      "        [0.5323],\n",
      "        [0.3300],\n",
      "        [0.1215],\n",
      "        [0.6119],\n",
      "        [0.2727],\n",
      "        [0.2328],\n",
      "        [0.2223],\n",
      "        [0.4492],\n",
      "        [0.1783],\n",
      "        [0.2984],\n",
      "        [0.1402],\n",
      "        [0.3753],\n",
      "        [0.5146],\n",
      "        [0.5664],\n",
      "        [0.1386],\n",
      "        [0.5176],\n",
      "        [0.3418],\n",
      "        [0.4264],\n",
      "        [0.2951],\n",
      "        [0.3146],\n",
      "        [0.2503],\n",
      "        [0.2626],\n",
      "        [0.4131],\n",
      "        [0.6246],\n",
      "        [0.2263],\n",
      "        [0.2858],\n",
      "        [0.3238],\n",
      "        [0.2102],\n",
      "        [0.0317],\n",
      "        [0.2886],\n",
      "        [0.2948],\n",
      "        [0.1589],\n",
      "        [0.3761],\n",
      "        [0.5415],\n",
      "        [0.4235],\n",
      "        [0.3364],\n",
      "        [0.2868],\n",
      "        [0.5290],\n",
      "        [0.4209],\n",
      "        [0.5670],\n",
      "        [0.3148],\n",
      "        [0.3670],\n",
      "        [0.0524],\n",
      "        [0.3666],\n",
      "        [0.3802],\n",
      "        [0.3300],\n",
      "        [0.3438],\n",
      "        [0.4309],\n",
      "        [0.6051],\n",
      "        [0.0899],\n",
      "        [0.1343],\n",
      "        [0.2311],\n",
      "        [0.3058],\n",
      "        [0.4154],\n",
      "        [0.6283],\n",
      "        [0.0408],\n",
      "        [0.3855],\n",
      "        [0.0223],\n",
      "        [0.3343],\n",
      "        [0.2507],\n",
      "        [0.3169],\n",
      "        [0.5415],\n",
      "        [0.3083],\n",
      "        [0.3357],\n",
      "        [0.1605],\n",
      "        [0.0700],\n",
      "        [0.1678],\n",
      "        [0.1966],\n",
      "        [0.5148],\n",
      "        [0.5054],\n",
      "        [0.2282],\n",
      "        [0.2893],\n",
      "        [0.6004],\n",
      "        [0.2914],\n",
      "        [0.5054],\n",
      "        [0.5212],\n",
      "        [0.0341],\n",
      "        [0.0417],\n",
      "        [0.2527],\n",
      "        [0.1822],\n",
      "        [0.4039],\n",
      "        [0.3273],\n",
      "        [0.1256],\n",
      "        [0.3246],\n",
      "        [0.0920],\n",
      "        [0.4150],\n",
      "        [0.5532],\n",
      "        [0.4692],\n",
      "        [0.3094],\n",
      "        [0.3195],\n",
      "        [0.6400],\n",
      "        [0.0606],\n",
      "        [0.3698],\n",
      "        [0.5107],\n",
      "        [0.4366],\n",
      "        [0.2706],\n",
      "        [0.5845],\n",
      "        [0.6385],\n",
      "        [0.4261],\n",
      "        [0.5792],\n",
      "        [0.3345],\n",
      "        [0.2198],\n",
      "        [0.2148],\n",
      "        [0.1433],\n",
      "        [0.0500],\n",
      "        [0.2003],\n",
      "        [0.4024],\n",
      "        [0.0432],\n",
      "        [0.4174],\n",
      "        [0.3270],\n",
      "        [0.0514],\n",
      "        [0.2531],\n",
      "        [0.1790],\n",
      "        [0.5547],\n",
      "        [0.0617],\n",
      "        [0.1226],\n",
      "        [0.0793],\n",
      "        [0.4763],\n",
      "        [0.3398],\n",
      "        [0.1597],\n",
      "        [0.1187],\n",
      "        [0.3781],\n",
      "        [0.5536],\n",
      "        [0.2464],\n",
      "        [0.1908],\n",
      "        [0.3533],\n",
      "        [0.2608],\n",
      "        [0.2306],\n",
      "        [0.1072],\n",
      "        [0.2652],\n",
      "        [0.2879],\n",
      "        [0.5815],\n",
      "        [0.1865],\n",
      "        [0.5721],\n",
      "        [0.0283],\n",
      "        [0.3400],\n",
      "        [0.2338],\n",
      "        [0.4620],\n",
      "        [0.5648],\n",
      "        [0.5753],\n",
      "        [0.5809],\n",
      "        [0.3044],\n",
      "        [0.4960],\n",
      "        [0.0957],\n",
      "        [0.0955],\n",
      "        [0.1708],\n",
      "        [0.1745],\n",
      "        [0.1705],\n",
      "        [0.2894],\n",
      "        [0.3451],\n",
      "        [0.0236],\n",
      "        [0.2364],\n",
      "        [0.5249],\n",
      "        [0.2425],\n",
      "        [0.0329],\n",
      "        [0.1960],\n",
      "        [0.1162],\n",
      "        [0.5177],\n",
      "        [0.3334],\n",
      "        [0.6465],\n",
      "        [0.0742],\n",
      "        [0.5314],\n",
      "        [0.2134],\n",
      "        [0.2095],\n",
      "        [0.3313],\n",
      "        [0.1994],\n",
      "        [0.4118],\n",
      "        [0.3452],\n",
      "        [0.1128],\n",
      "        [0.5954],\n",
      "        [0.0248],\n",
      "        [0.4743],\n",
      "        [0.6062],\n",
      "        [0.3657],\n",
      "        [0.2611],\n",
      "        [0.5665],\n",
      "        [0.4987],\n",
      "        [0.5251],\n",
      "        [0.3240],\n",
      "        [0.6193],\n",
      "        [0.3966],\n",
      "        [0.1576],\n",
      "        [0.3639],\n",
      "        [0.0987],\n",
      "        [0.2580],\n",
      "        [0.6035],\n",
      "        [0.0921],\n",
      "        [0.5584],\n",
      "        [0.3560],\n",
      "        [0.3278],\n",
      "        [0.4183],\n",
      "        [0.1393],\n",
      "        [0.0231],\n",
      "        [0.4396],\n",
      "        [0.2938],\n",
      "        [0.3147],\n",
      "        [0.3681],\n",
      "        [0.2901],\n",
      "        [0.4993],\n",
      "        [0.4321],\n",
      "        [0.2080],\n",
      "        [0.2176],\n",
      "        [0.4027],\n",
      "        [0.2097],\n",
      "        [0.1388],\n",
      "        [0.5057],\n",
      "        [0.3276],\n",
      "        [0.3502],\n",
      "        [0.2969],\n",
      "        [0.3587],\n",
      "        [0.1743],\n",
      "        [0.2221],\n",
      "        [0.5507],\n",
      "        [0.6302],\n",
      "        [0.6386],\n",
      "        [0.6427],\n",
      "        [0.2957],\n",
      "        [0.6135],\n",
      "        [0.2694],\n",
      "        [0.0842],\n",
      "        [0.3028],\n",
      "        [0.5338],\n",
      "        [0.3712],\n",
      "        [0.1218],\n",
      "        [0.4719],\n",
      "        [0.4191],\n",
      "        [0.2398],\n",
      "        [0.1774],\n",
      "        [0.5937],\n",
      "        [0.0362],\n",
      "        [0.5761],\n",
      "        [0.0235],\n",
      "        [0.5843],\n",
      "        [0.0856],\n",
      "        [0.1103],\n",
      "        [0.2473],\n",
      "        [0.0241],\n",
      "        [0.2286],\n",
      "        [0.3633],\n",
      "        [0.1533],\n",
      "        [0.0465],\n",
      "        [0.2815],\n",
      "        [0.5424],\n",
      "        [0.3028],\n",
      "        [0.4361],\n",
      "        [0.4879],\n",
      "        [0.1350],\n",
      "        [0.1938],\n",
      "        [0.0472],\n",
      "        [0.5235],\n",
      "        [0.1662],\n",
      "        [0.0508],\n",
      "        [0.2982],\n",
      "        [0.0985],\n",
      "        [0.4757],\n",
      "        [0.2618],\n",
      "        [0.2820],\n",
      "        [0.1683],\n",
      "        [0.1129],\n",
      "        [0.2527],\n",
      "        [0.0681],\n",
      "        [0.4423],\n",
      "        [0.5319],\n",
      "        [0.2554],\n",
      "        [0.3360],\n",
      "        [0.0883],\n",
      "        [0.5235],\n",
      "        [0.1974],\n",
      "        [0.0716],\n",
      "        [0.1550],\n",
      "        [0.6352],\n",
      "        [0.0281],\n",
      "        [0.5840],\n",
      "        [0.2068],\n",
      "        [0.5662],\n",
      "        [0.4296],\n",
      "        [0.1680],\n",
      "        [0.5585],\n",
      "        [0.4151],\n",
      "        [0.2857],\n",
      "        [0.2864],\n",
      "        [0.3704],\n",
      "        [0.2626],\n",
      "        [0.1752],\n",
      "        [0.2293],\n",
      "        [0.3414],\n",
      "        [0.3715],\n",
      "        [0.5151],\n",
      "        [0.1835],\n",
      "        [0.3443],\n",
      "        [0.5213],\n",
      "        [0.1524],\n",
      "        [0.4233],\n",
      "        [0.6085],\n",
      "        [0.1509],\n",
      "        [0.2531],\n",
      "        [0.3787],\n",
      "        [0.5136],\n",
      "        [0.2465],\n",
      "        [0.2119],\n",
      "        [0.4422],\n",
      "        [0.2772],\n",
      "        [0.3057],\n",
      "        [0.3704],\n",
      "        [0.0440],\n",
      "        [0.5768],\n",
      "        [0.2130],\n",
      "        [0.6335],\n",
      "        [0.1700],\n",
      "        [0.0218],\n",
      "        [0.3683],\n",
      "        [0.2342],\n",
      "        [0.1257],\n",
      "        [0.2446],\n",
      "        [0.2079],\n",
      "        [0.3562],\n",
      "        [0.3982],\n",
      "        [0.5317]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "edge_probs = model(data)\n",
    "k_probs = []\n",
    "\n",
    "residuals = []\n",
    "for i, e in enumerate(G.edges()):\n",
    "  u, v = e\n",
    "  p = G[u][v]['weight']\n",
    "  residuals.append(abs(p - edge_probs[i].item()))\n",
    "  k_probs.append(edge_probs[i].item())\n",
    "\n",
    "probs.append(k_probs)\n",
    "l1_errors.append(sum(residuals) / len(residuals))\n",
    "medians.append(np.median(residuals))\n",
    "quartile1s.append(np.percentile(residuals, 25))\n",
    "quartile3s.append(np.percentile(residuals, 75))\n",
    "\n",
    "print(f\"MAE Error: {l1_errors[0]}\")\n",
    "print(f\"Median: {medians[0]}, Q1: {quartile1s[0]}, Q3: {quartile3s[0]}\")\n",
    "print(edge_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots()\n",
    "fig.plot((50, 100, 150, 200, 250), l1_errors, label=\"Avg L1 Error\", linestyle='--', marker='o', color='gray', markerfacecolor='blue')\n",
    "#fig.scatter((50, 100, 150, 200, 250), medians, label=\"Median\")\n",
    "#fig.scatter((50, 100, 150, 200, 250), quartile1s, label=\"1st Quartile\")\n",
    "#fig.scatter((50, 100, 150, 200, 250), quartile3s, label=\"3rd Quartile\")\n",
    "\n",
    "plt.xlabel(\"Number of Cascades\")\n",
    "plt.ylabel(r\"Average L1 Error $(\\frac{1}{m} \\sum_{e \\in E} | p_e - \\hat{p}_e |)$\")\n",
    "#plt.legend()\n",
    "plt.savefig(\"figs/m1_plot.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate((50, 100, 150, 200, 250)):\n",
    "  with open(path / f\"probs/{k}.txt\", \"w\") as fh:\n",
    "    for p in probs[i]:\n",
    "      fh.write(f\"{p:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14916746752274268, 0.09472653568538095, 0.07688556758801862, 0.06718936878994637, 0.06007313081040892]\n"
     ]
    }
   ],
   "source": [
    "print(l1_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
